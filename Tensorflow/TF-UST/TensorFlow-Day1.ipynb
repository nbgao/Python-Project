{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Hello World ！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow\\xef\\xbc\\x81'\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant(\"Hello, TensorFlow！\")\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0)\n",
    "node3 = tf.add(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1: Tensor(\"Const_1:0\", shape=(), dtype=float32) node2: Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "node3: Tensor(\"Add:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"node1:\", node1, \"node2:\", node2)\n",
    "print(\"node3:\", node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1, node2):  [3.0, 4.0]\n",
      "sess.run(node3) 7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"sess.run(node1, node2): \", sess.run([node1, node2]))\n",
    "print(\"sess.run(node3)\", sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b\n",
    "\n",
    "print(sess.run(adder_node, feed_dict={a: 3, b: 4.5}))\n",
    "print(sess.run(adder_node, feed_dict={a: [1,3], b:[2,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything is Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1.0, 2.0, 3.0]], [[7.0, 8.0, 9.0]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1., 2., 3.]\n",
    "[[1., 2., 3.], [4., 5., 6.]]\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**———————————————————————————————————————**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ cost=\\frac{1}{m}\\sum_{i=1}^{m}(H(x^{(i)}-y^{(i)}))^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ H(x)=Wx+b $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$cost(W,b)=\\frac{1}{m}\\sum_{i=1}^{m}(H(x^{(i)}-y^{(i)}))^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Hypothesis in TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(x)=Wx$  \n",
    "y_model = tf.mul(x, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$cost(W)=\\frac{1}{m}\\sum_{i=1}^{m}(Wx^{(i)}-y^{(i)})^2$\n",
    "\n",
    "cost = tf.square(Y - y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: Minimize Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\min_{W,b} cost(W,b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$cost(W)=\\frac{1}{2m}\\sum_{i=1}^{m}(Wx^{(i)}-y^{(i)})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W:=W-\\alpha \\frac{\\partial }{\\partial W}cost(W) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Algorithm in TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W:=W-\\alpha \\frac{\\partial }{\\partial W}cost(W) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W:=W-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}(Wx^{(i)}-y^{(i)})x^{(i)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost = tf.square(Y - y_model) <br>\n",
    "train_op = tf.train.GradientDescentOptimizer(0.01.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build graph using TF operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ H(x)=Wx+b $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = X_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$cost(W,b)=\\frac{1}{m}\\sum_{i=1}^{m}(H(x^{(i)}-y^{(i)}))^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run/update graph and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.6462 [-0.57791179] [-0.30631071]\n",
      "20 0.137346 [ 0.72714078] [ 0.24955824]\n",
      "40 0.0136143 [ 0.85716921] [ 0.28938872]\n",
      "60 0.0113572 [ 0.87504196] [ 0.28069791]\n",
      "80 0.0103056 [ 0.88197726] [ 0.26797354]\n",
      "100 0.00935968 [ 0.88762492] [ 0.25542426]\n",
      "120 0.0085006 [ 0.89291584] [ 0.2434245]\n",
      "140 0.00772038 [ 0.89794934] [ 0.23198485]\n",
      "160 0.00701177 [ 0.90274537] [ 0.22108248]\n",
      "180 0.00636821 [ 0.90731597] [ 0.21069247]\n"
     ]
    }
   ],
   "source": [
    "for step in range(200):\n",
    "    sess.run(train)\n",
    "    if step%20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00581161 [ 0.91167188] [ 0.20079069]\n",
      "20 0.00527821 [ 0.91582292] [ 0.19135427]\n",
      "40 0.00479376 [ 0.91977888] [ 0.18236139]\n",
      "60 0.00435376 [ 0.923549] [ 0.1737911]\n",
      "80 0.00395416 [ 0.9271419] [ 0.16562356]\n",
      "100 0.00359123 [ 0.93056595] [ 0.15783988]\n",
      "120 0.00326161 [ 0.93382913] [ 0.15042198]\n",
      "140 0.00296225 [ 0.93693894] [ 0.14335269]\n",
      "160 0.00269037 [ 0.9399026] [ 0.13661562]\n",
      "180 0.00244343 [ 0.94272691] [ 0.13019517]\n"
     ]
    }
   ],
   "source": [
    "for step in range(200):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],\n",
    "                                         feed_dict={X:[1,2,3], Y:[1,2,3]})\n",
    "    if step%20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**———————————————————————————————————————**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (Binaray Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ H(X)=sigmoid(XW)=\\frac{1}{1+e^{-XW}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ cost(W)=-\\frac{1}{m}\\sum{ylog(H(x)) + (1-y)(log(1-H(x)))} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $W:=W-\\alpha \\frac{\\partial }{\\partial W}cost(W) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Classification in TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ H(X)=sigmoid(XW)=\\frac{1}{1+e^{-XW}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ cost(W)=-\\frac{1}{m}\\sum{ylog(H(x)) + (1-y)(log(1-H(x)))} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.95966\n",
      "200 0.684617\n",
      "400 0.640791\n",
      "600 0.60862\n",
      "800 0.582137\n",
      "1000 0.558813\n",
      "1200 0.537483\n",
      "1400 0.517576\n",
      "1600 0.498797\n",
      "1800 0.480985\n",
      "2000 0.464045\n",
      "2200 0.447917\n",
      "2400 0.432558\n",
      "2600 0.417932\n",
      "2800 0.404008\n",
      "3000 0.390755\n",
      "3200 0.378145\n",
      "3400 0.366148\n",
      "3600 0.354736\n",
      "3800 0.343879\n",
      "4000 0.33355\n",
      "4200 0.323721\n",
      "4400 0.314366\n",
      "4600 0.305458\n",
      "4800 0.296975\n",
      "5000 0.288891\n",
      "5200 0.281185\n",
      "5400 0.273834\n",
      "5600 0.26682\n",
      "5800 0.260123\n",
      "6000 0.253725\n",
      "6200 0.247608\n",
      "6400 0.241758\n",
      "6600 0.236159\n",
      "6800 0.230797\n",
      "7000 0.225658\n",
      "7200 0.220731\n",
      "7400 0.216005\n",
      "7600 0.211467\n",
      "7800 0.207108\n",
      "8000 0.202919\n",
      "8200 0.198889\n",
      "8400 0.195012\n",
      "8600 0.191279\n",
      "8800 0.187683\n",
      "9000 0.184216\n",
      "9200 0.180873\n",
      "9400 0.177647\n",
      "9600 0.174532\n",
      "9800 0.171524\n",
      "10000 0.168616\n",
      "\n",
      "Hypothesis:  [[ 0.03917269]\n",
      " [ 0.16890655]\n",
      " [ 0.34297049]\n",
      " [ 0.76447439]\n",
      " [ 0.92842555]\n",
      " [ 0.9765029 ]] \n",
      "Correct (Y):  [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step%200 == 0:\n",
    "            print(step, cost_val)\n",
    "    \n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "xy = np.loadtxt('./Data/data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.95779\n",
      "200 1.25214\n",
      "400 1.20498\n",
      "600 1.18918\n",
      "800 1.17684\n",
      "1000 1.16645\n",
      "1200 1.15762\n",
      "1400 1.15005\n",
      "1600 1.14353\n",
      "1800 1.13788\n",
      "2000 1.13293\n",
      "2200 1.12858\n",
      "2400 1.12473\n",
      "2600 1.1213\n",
      "2800 1.11822\n",
      "3000 1.11544\n",
      "3200 1.11292\n",
      "3400 1.11063\n",
      "3600 1.10853\n",
      "3800 1.1066\n",
      "4000 1.10482\n",
      "4200 1.10317\n",
      "4400 1.10164\n",
      "4600 1.10022\n",
      "4800 1.09889\n",
      "5000 1.09764\n",
      "5200 1.09647\n",
      "5400 1.09538\n",
      "5600 1.09434\n",
      "5800 1.09337\n",
      "6000 1.09245\n",
      "6200 1.09158\n",
      "6400 1.09075\n",
      "6600 1.08997\n",
      "6800 1.08923\n",
      "7000 1.08852\n",
      "7200 1.08785\n",
      "7400 1.08721\n",
      "7600 1.08661\n",
      "7800 1.08603\n",
      "8000 1.08548\n",
      "8200 1.08495\n",
      "8400 1.08445\n",
      "8600 1.08397\n",
      "8800 1.08351\n",
      "9000 1.08307\n",
      "9200 1.08265\n",
      "9400 1.08225\n",
      "9600 1.08186\n",
      "9800 1.0815\n",
      "10000 1.08114\n",
      "\n",
      "Hypothesis:  [[ 0.30963969]\n",
      " [ 0.54633403]\n",
      " [ 0.20551956]\n",
      " [ 0.55224574]\n",
      " [ 0.33224738]\n",
      " [ 0.37373832]\n",
      " [ 0.5858373 ]\n",
      " [ 0.40103006]\n",
      " [ 0.21512079]\n",
      " [ 0.29049489]\n",
      " [ 0.33396682]\n",
      " [ 0.21152961]\n",
      " [ 0.25567296]\n",
      " [ 0.3094224 ]\n",
      " [ 0.44862673]\n",
      " [ 0.299712  ]\n",
      " [ 0.39181951]\n",
      " [ 0.57573074]\n",
      " [ 0.40403852]\n",
      " [ 0.28589609]\n",
      " [ 0.39180127]\n",
      " [ 0.14033689]\n",
      " [ 0.35396063]\n",
      " [ 0.37575054]\n",
      " [ 0.27980435]\n",
      " [ 0.50202376]\n",
      " [ 0.30048549]\n",
      " [ 0.31424987]\n",
      " [ 0.44917452]\n",
      " [ 0.2443196 ]\n",
      " [ 0.5623495 ]\n",
      " [ 0.3849552 ]\n",
      " [ 0.36165226]\n",
      " [ 0.45205551]\n",
      " [ 0.28095049]\n",
      " [ 0.41428539]\n",
      " [ 0.47936025]\n",
      " [ 0.36326155]\n",
      " [ 0.24645467]\n",
      " [ 0.27292758]\n",
      " [ 0.41485021]\n",
      " [ 0.16168503]\n",
      " [ 0.28190154]\n",
      " [ 0.17681037]\n",
      " [ 0.33842307]\n",
      " [ 0.55728453]\n",
      " [ 0.45729372]\n",
      " [ 0.43070996]\n",
      " [ 0.43977404]\n",
      " [ 0.53976202]\n",
      " [ 0.51188385]\n",
      " [ 0.19751148]\n",
      " [ 0.29182509]\n",
      " [ 0.69401193]\n",
      " [ 0.21340837]\n",
      " [ 0.29340464]\n",
      " [ 0.21407829]\n",
      " [ 0.41399458]\n",
      " [ 0.54437828]\n",
      " [ 0.32434922]\n",
      " [ 0.6306712 ]\n",
      " [ 0.34433126]\n",
      " [ 0.40680525]\n",
      " [ 0.47022063]\n",
      " [ 0.35255441]\n",
      " [ 0.33894986]\n",
      " [ 0.51683551]\n",
      " [ 0.27559215]\n",
      " [ 0.46207991]\n",
      " [ 0.3330988 ]\n",
      " [ 0.26480916]\n",
      " [ 0.33272755]\n",
      " [ 0.51899958]\n",
      " [ 0.57922989]\n",
      " [ 0.52454579]\n",
      " [ 0.46242696]\n",
      " [ 0.34653953]\n",
      " [ 0.46480629]\n",
      " [ 0.5575071 ]\n",
      " [ 0.55409545]\n",
      " [ 0.45896524]\n",
      " [ 0.47004515]\n",
      " [ 0.21992384]\n",
      " [ 0.39505839]\n",
      " [ 0.38795292]\n",
      " [ 0.46363735]\n",
      " [ 0.31885105]\n",
      " [ 0.48891774]\n",
      " [ 0.58814472]\n",
      " [ 0.37594533]\n",
      " [ 0.45865884]\n",
      " [ 0.35720184]\n",
      " [ 0.31535298]\n",
      " [ 0.32778379]\n",
      " [ 0.53641081]\n",
      " [ 0.64201921]\n",
      " [ 0.52307892]\n",
      " [ 0.29372048]\n",
      " [ 0.22755457]\n",
      " [ 0.32138884]\n",
      " [ 0.28871974]\n",
      " [ 0.5299899 ]\n",
      " [ 0.47205415]\n",
      " [ 0.43272305]\n",
      " [ 0.29401201]\n",
      " [ 0.36836472]\n",
      " [ 0.53403312]\n",
      " [ 0.39861169]\n",
      " [ 0.24001724]\n",
      " [ 0.33278367]\n",
      " [ 0.4603838 ]\n",
      " [ 0.52775538]\n",
      " [ 0.31015617]\n",
      " [ 0.25516349]\n",
      " [ 0.35419959]\n",
      " [ 0.55466455]\n",
      " [ 0.51543331]\n",
      " [ 0.48720387]\n",
      " [ 0.18518047]\n",
      " [ 0.42680803]\n",
      " [ 0.40865207]\n",
      " [ 0.34602574]\n",
      " [ 0.35209695]\n",
      " [ 0.59120429]\n",
      " [ 0.38261655]\n",
      " [ 0.42597154]\n",
      " [ 0.36650541]\n",
      " [ 0.37218866]\n",
      " [ 0.27045763]\n",
      " [ 0.36378518]\n",
      " [ 0.26120472]\n",
      " [ 0.49297556]\n",
      " [ 0.49074209]\n",
      " [ 0.44287747]\n",
      " [ 0.44837612]\n",
      " [ 0.48249888]\n",
      " [ 0.28570971]\n",
      " [ 0.4423413 ]\n",
      " [ 0.35545322]\n",
      " [ 0.41390997]\n",
      " [ 0.48894954]\n",
      " [ 0.41478136]\n",
      " [ 0.31761351]\n",
      " [ 0.45521799]\n",
      " [ 0.56346107]\n",
      " [ 0.40749994]\n",
      " [ 0.30260387]\n",
      " [ 0.53799057]\n",
      " [ 0.29795983]\n",
      " [ 0.41179717]\n",
      " [ 0.21566883]\n",
      " [ 0.24805653]\n",
      " [ 0.18148565]\n",
      " [ 0.2327276 ]\n",
      " [ 0.5612312 ]\n",
      " [ 0.47126937]\n",
      " [ 0.49529451]\n",
      " [ 0.20820206]\n",
      " [ 0.25336316]\n",
      " [ 0.41866943]\n",
      " [ 0.36037293]\n",
      " [ 0.53284705]\n",
      " [ 0.25971457]\n",
      " [ 0.43737558]\n",
      " [ 0.34244472]\n",
      " [ 0.36630827]\n",
      " [ 0.40729919]\n",
      " [ 0.37646818]\n",
      " [ 0.39189932]\n",
      " [ 0.34152856]\n",
      " [ 0.53965056]\n",
      " [ 0.50712478]\n",
      " [ 0.56708592]\n",
      " [ 0.19218448]\n",
      " [ 0.45624989]\n",
      " [ 0.20074917]\n",
      " [ 0.29464766]\n",
      " [ 0.28310597]\n",
      " [ 0.44824693]\n",
      " [ 0.39078364]\n",
      " [ 0.48651183]\n",
      " [ 0.55086648]\n",
      " [ 0.31192282]\n",
      " [ 0.20416804]\n",
      " [ 0.24278809]\n",
      " [ 0.2369757 ]\n",
      " [ 0.36069775]\n",
      " [ 0.28691813]\n",
      " [ 0.4619503 ]\n",
      " [ 0.34291708]\n",
      " [ 0.26894546]\n",
      " [ 0.32556081]\n",
      " [ 0.59808445]\n",
      " [ 0.22373793]\n",
      " [ 0.49946567]\n",
      " [ 0.46732941]\n",
      " [ 0.3844195 ]\n",
      " [ 0.35987547]\n",
      " [ 0.40498281]\n",
      " [ 0.29114017]\n",
      " [ 0.43870452]\n",
      " [ 0.48734722]\n",
      " [ 0.45184892]\n",
      " [ 0.4247759 ]\n",
      " [ 0.1875699 ]\n",
      " [ 0.19187629]\n",
      " [ 0.5213446 ]\n",
      " [ 0.19412343]\n",
      " [ 0.58514935]\n",
      " [ 0.22554994]\n",
      " [ 0.20120302]\n",
      " [ 0.32387781]\n",
      " [ 0.36379233]\n",
      " [ 0.25718126]\n",
      " [ 0.41013253]\n",
      " [ 0.36921659]\n",
      " [ 0.48032764]\n",
      " [ 0.41689241]\n",
      " [ 0.25775355]\n",
      " [ 0.23231821]\n",
      " [ 0.40761736]\n",
      " [ 0.3601031 ]\n",
      " [ 0.48314095]\n",
      " [ 0.47475159]\n",
      " [ 0.39359578]\n",
      " [ 0.30840549]\n",
      " [ 0.15370005]\n",
      " [ 0.34270129]\n",
      " [ 0.24192527]\n",
      " [ 0.32515034]\n",
      " [ 0.48015514]\n",
      " [ 0.36624813]\n",
      " [ 0.53743631]\n",
      " [ 0.21847884]\n",
      " [ 0.17296253]\n",
      " [ 0.22866355]\n",
      " [ 0.37573826]\n",
      " [ 0.57081485]\n",
      " [ 0.45852336]\n",
      " [ 0.35974002]\n",
      " [ 0.4322274 ]\n",
      " [ 0.2930136 ]\n",
      " [ 0.19267642]\n",
      " [ 0.36539528]\n",
      " [ 0.20911241]\n",
      " [ 0.37542701]\n",
      " [ 0.41319877]\n",
      " [ 0.46811742]\n",
      " [ 0.30779555]\n",
      " [ 0.48097721]\n",
      " [ 0.49905407]\n",
      " [ 0.51930261]\n",
      " [ 0.4622339 ]\n",
      " [ 0.45964614]\n",
      " [ 0.46056119]\n",
      " [ 0.27380756]\n",
      " [ 0.23388006]\n",
      " [ 0.32148677]\n",
      " [ 0.46312127]\n",
      " [ 0.37637272]\n",
      " [ 0.39687333]\n",
      " [ 0.44931585]\n",
      " [ 0.30276933]\n",
      " [ 0.34613231]\n",
      " [ 0.45679635]\n",
      " [ 0.33225098]\n",
      " [ 0.34939471]\n",
      " [ 0.48441619]\n",
      " [ 0.35827184]\n",
      " [ 0.49993718]\n",
      " [ 0.40799034]\n",
      " [ 0.38786429]\n",
      " [ 0.48854861]\n",
      " [ 0.44382638]\n",
      " [ 0.38502339]\n",
      " [ 0.47785974]\n",
      " [ 0.27960858]\n",
      " [ 0.33520654]\n",
      " [ 0.3207927 ]\n",
      " [ 0.22844452]\n",
      " [ 0.40813962]\n",
      " [ 0.23929878]\n",
      " [ 0.31499171]\n",
      " [ 0.53090316]\n",
      " [ 0.39149258]\n",
      " [ 0.45510113]\n",
      " [ 0.41102064]\n",
      " [ 0.29917952]\n",
      " [ 0.40129384]\n",
      " [ 0.33950979]\n",
      " [ 0.29733774]\n",
      " [ 0.31795815]\n",
      " [ 0.30630913]\n",
      " [ 0.41334534]\n",
      " [ 0.38514343]\n",
      " [ 0.23808736]\n",
      " [ 0.34760624]\n",
      " [ 0.46351913]\n",
      " [ 0.29184169]\n",
      " [ 0.2855725 ]\n",
      " [ 0.36172   ]\n",
      " [ 0.2886323 ]\n",
      " [ 0.38992089]\n",
      " [ 0.33163932]\n",
      " [ 0.37451515]\n",
      " [ 0.55527556]\n",
      " [ 0.38154322]\n",
      " [ 0.29648286]\n",
      " [ 0.49975151]\n",
      " [ 0.37405577]\n",
      " [ 0.43477091]\n",
      " [ 0.4618412 ]\n",
      " [ 0.20203568]\n",
      " [ 0.40705702]\n",
      " [ 0.19023816]\n",
      " [ 0.42799395]\n",
      " [ 0.42201489]\n",
      " [ 0.40861955]\n",
      " [ 0.20944999]\n",
      " [ 0.44630522]\n",
      " [ 0.30634201]\n",
      " [ 0.39337584]\n",
      " [ 0.20987259]\n",
      " [ 0.3817434 ]\n",
      " [ 0.43651155]\n",
      " [ 0.38473678]\n",
      " [ 0.56388164]\n",
      " [ 0.25042817]\n",
      " [ 0.37868664]\n",
      " [ 0.52756613]\n",
      " [ 0.21784745]\n",
      " [ 0.38261622]\n",
      " [ 0.37658551]\n",
      " [ 0.23899592]\n",
      " [ 0.18586135]\n",
      " [ 0.38536799]\n",
      " [ 0.47059298]\n",
      " [ 0.46793443]\n",
      " [ 0.3152324 ]\n",
      " [ 0.44739977]\n",
      " [ 0.30513749]\n",
      " [ 0.41606057]\n",
      " [ 0.41762248]\n",
      " [ 0.50412273]\n",
      " [ 0.43311501]\n",
      " [ 0.42263839]\n",
      " [ 0.28335336]\n",
      " [ 0.58037066]\n",
      " [ 0.53430891]\n",
      " [ 0.44846272]\n",
      " [ 0.20753771]\n",
      " [ 0.40361717]\n",
      " [ 0.37983873]\n",
      " [ 0.43856516]\n",
      " [ 0.16856904]\n",
      " [ 0.21523097]\n",
      " [ 0.29598194]\n",
      " [ 0.35197118]\n",
      " [ 0.29747888]\n",
      " [ 0.31203067]\n",
      " [ 0.49793375]\n",
      " [ 0.34478778]\n",
      " [ 0.52671403]\n",
      " [ 0.47666618]\n",
      " [ 0.28380525]\n",
      " [ 0.15603566]\n",
      " [ 0.37184259]\n",
      " [ 0.52960551]\n",
      " [ 0.45912045]\n",
      " [ 0.4017424 ]\n",
      " [ 0.27547258]\n",
      " [ 0.42137796]\n",
      " [ 0.50159711]\n",
      " [ 0.25687218]\n",
      " [ 0.3122611 ]\n",
      " [ 0.40205756]\n",
      " [ 0.46029806]\n",
      " [ 0.51084995]\n",
      " [ 0.49554577]\n",
      " [ 0.39468476]\n",
      " [ 0.48554525]\n",
      " [ 0.39522612]\n",
      " [ 0.34512067]\n",
      " [ 0.31565696]\n",
      " [ 0.44228345]\n",
      " [ 0.48891899]\n",
      " [ 0.22195899]\n",
      " [ 0.45518994]\n",
      " [ 0.42995122]\n",
      " [ 0.22979158]\n",
      " [ 0.37665281]\n",
      " [ 0.49188039]\n",
      " [ 0.34968123]\n",
      " [ 0.48926803]\n",
      " [ 0.21059851]\n",
      " [ 0.47703776]\n",
      " [ 0.28049868]\n",
      " [ 0.53497982]\n",
      " [ 0.26919433]\n",
      " [ 0.44178355]\n",
      " [ 0.39453128]\n",
      " [ 0.43876374]\n",
      " [ 0.14993329]\n",
      " [ 0.23631474]\n",
      " [ 0.35516867]\n",
      " [ 0.40464258]\n",
      " [ 0.27258077]\n",
      " [ 0.35225329]\n",
      " [ 0.356343  ]\n",
      " [ 0.21806629]\n",
      " [ 0.47415027]\n",
      " [ 0.29159775]\n",
      " [ 0.49300098]\n",
      " [ 0.38892993]\n",
      " [ 0.31147423]\n",
      " [ 0.51801121]\n",
      " [ 0.42672271]\n",
      " [ 0.4838888 ]\n",
      " [ 0.26123649]\n",
      " [ 0.19579221]\n",
      " [ 0.46361372]\n",
      " [ 0.25530788]\n",
      " [ 0.23370601]\n",
      " [ 0.46558112]\n",
      " [ 0.47900665]\n",
      " [ 0.49911013]\n",
      " [ 0.52715862]\n",
      " [ 0.3139216 ]\n",
      " [ 0.53605258]\n",
      " [ 0.3235645 ]\n",
      " [ 0.28384948]\n",
      " [ 0.27199608]\n",
      " [ 0.55463046]\n",
      " [ 0.32898441]\n",
      " [ 0.14986879]\n",
      " [ 0.51814878]\n",
      " [ 0.41969615]\n",
      " [ 0.37131777]\n",
      " [ 0.47642741]\n",
      " [ 0.10738461]\n",
      " [ 0.4710356 ]\n",
      " [ 0.38049236]\n",
      " [ 0.40824646]\n",
      " [ 0.37599674]\n",
      " [ 0.56271988]\n",
      " [ 0.32199281]\n",
      " [ 0.46114472]\n",
      " [ 0.43702465]\n",
      " [ 0.49893963]\n",
      " [ 0.25659278]\n",
      " [ 0.40701625]\n",
      " [ 0.49137208]\n",
      " [ 0.35468271]\n",
      " [ 0.38033327]\n",
      " [ 0.55873597]\n",
      " [ 0.48693961]\n",
      " [ 0.48937106]\n",
      " [ 0.26307866]\n",
      " [ 0.45822302]\n",
      " [ 0.60689753]\n",
      " [ 0.43254137]\n",
      " [ 0.40151358]\n",
      " [ 0.2329677 ]\n",
      " [ 0.27693734]\n",
      " [ 0.32493079]\n",
      " [ 0.40548536]\n",
      " [ 0.27985772]\n",
      " [ 0.412025  ]\n",
      " [ 0.33579603]\n",
      " [ 0.36644191]\n",
      " [ 0.39753494]\n",
      " [ 0.34413525]\n",
      " [ 0.34756359]\n",
      " [ 0.29639727]\n",
      " [ 0.31645456]\n",
      " [ 0.55049694]\n",
      " [ 0.43673772]\n",
      " [ 0.29791045]\n",
      " [ 0.31131753]\n",
      " [ 0.37775749]\n",
      " [ 0.20780998]\n",
      " [ 0.493099  ]\n",
      " [ 0.17542534]\n",
      " [ 0.50760257]\n",
      " [ 0.45700732]\n",
      " [ 0.4752714 ]\n",
      " [ 0.37698132]\n",
      " [ 0.52830958]\n",
      " [ 0.2615099 ]\n",
      " [ 0.40793461]\n",
      " [ 0.52293235]\n",
      " [ 0.2082424 ]\n",
      " [ 0.26459879]\n",
      " [ 0.37923908]\n",
      " [ 0.51249164]\n",
      " [ 0.44185016]\n",
      " [ 0.47957462]\n",
      " [ 0.45378497]\n",
      " [ 0.46052426]\n",
      " [ 0.17796694]\n",
      " [ 0.42387953]\n",
      " [ 0.58252549]\n",
      " [ 0.36477959]\n",
      " [ 0.50351197]\n",
      " [ 0.40026245]\n",
      " [ 0.48862964]\n",
      " [ 0.48005897]\n",
      " [ 0.53443217]\n",
      " [ 0.28791928]\n",
      " [ 0.25067642]\n",
      " [ 0.52975941]\n",
      " [ 0.36761495]\n",
      " [ 0.55533212]\n",
      " [ 0.33851048]\n",
      " [ 0.4129675 ]\n",
      " [ 0.32637236]\n",
      " [ 0.39931324]\n",
      " [ 0.59327042]\n",
      " [ 0.53849202]\n",
      " [ 0.42210206]\n",
      " [ 0.38241309]\n",
      " [ 0.38907573]\n",
      " [ 0.4189738 ]\n",
      " [ 0.35030958]\n",
      " [ 0.44260639]\n",
      " [ 0.47918221]\n",
      " [ 0.53110349]\n",
      " [ 0.35740644]\n",
      " [ 0.35844278]\n",
      " [ 0.61265862]\n",
      " [ 0.28887072]\n",
      " [ 0.24728493]\n",
      " [ 0.40631238]\n",
      " [ 0.36132607]\n",
      " [ 0.43053257]\n",
      " [ 0.4407728 ]\n",
      " [ 0.4675481 ]\n",
      " [ 0.1621934 ]\n",
      " [ 0.19577976]\n",
      " [ 0.38439283]\n",
      " [ 0.23488958]\n",
      " [ 0.13550319]\n",
      " [ 0.46258721]\n",
      " [ 0.49381015]\n",
      " [ 0.36471504]\n",
      " [ 0.52230638]\n",
      " [ 0.53546524]\n",
      " [ 0.38190433]\n",
      " [ 0.47308549]\n",
      " [ 0.40171671]\n",
      " [ 0.43955937]\n",
      " [ 0.44897628]\n",
      " [ 0.36148873]\n",
      " [ 0.1827883 ]\n",
      " [ 0.48661003]\n",
      " [ 0.49413571]\n",
      " [ 0.39647827]\n",
      " [ 0.53240472]\n",
      " [ 0.46626851]\n",
      " [ 0.52032042]\n",
      " [ 0.29219943]\n",
      " [ 0.39261013]\n",
      " [ 0.5180909 ]\n",
      " [ 0.29414803]\n",
      " [ 0.44053325]\n",
      " [ 0.51912618]\n",
      " [ 0.26824734]\n",
      " [ 0.44786844]\n",
      " [ 0.51415253]\n",
      " [ 0.3533664 ]\n",
      " [ 0.33039108]\n",
      " [ 0.14343405]\n",
      " [ 0.23610422]\n",
      " [ 0.47895038]\n",
      " [ 0.41201562]\n",
      " [ 0.41420233]\n",
      " [ 0.39205259]\n",
      " [ 0.57870001]\n",
      " [ 0.32099921]\n",
      " [ 0.43458784]\n",
      " [ 0.19703624]\n",
      " [ 0.53193706]\n",
      " [ 0.33293557]\n",
      " [ 0.35464722]\n",
      " [ 0.3175762 ]\n",
      " [ 0.52812898]\n",
      " [ 0.3325589 ]\n",
      " [ 0.1798768 ]\n",
      " [ 0.51932371]\n",
      " [ 0.67607862]\n",
      " [ 0.23949236]\n",
      " [ 0.56068796]\n",
      " [ 0.40709794]\n",
      " [ 0.47576529]\n",
      " [ 0.39098817]\n",
      " [ 0.27821544]\n",
      " [ 0.23790643]\n",
      " [ 0.44711363]\n",
      " [ 0.17251766]\n",
      " [ 0.51074022]\n",
      " [ 0.24113336]\n",
      " [ 0.49355298]\n",
      " [ 0.50484473]\n",
      " [ 0.28642794]\n",
      " [ 0.18938699]\n",
      " [ 0.38926703]\n",
      " [ 0.31714067]\n",
      " [ 0.41437164]\n",
      " [ 0.30055887]\n",
      " [ 0.61155808]\n",
      " [ 0.36811346]\n",
      " [ 0.38940719]\n",
      " [ 0.34625939]\n",
      " [ 0.44242001]\n",
      " [ 0.13618141]\n",
      " [ 0.47602814]\n",
      " [ 0.46441936]\n",
      " [ 0.37978211]\n",
      " [ 0.37575719]\n",
      " [ 0.31426388]\n",
      " [ 0.33344615]\n",
      " [ 0.55487728]\n",
      " [ 0.38730687]\n",
      " [ 0.37732223]\n",
      " [ 0.43251699]\n",
      " [ 0.3640947 ]\n",
      " [ 0.47445193]\n",
      " [ 0.38524944]\n",
      " [ 0.43023065]\n",
      " [ 0.45377105]\n",
      " [ 0.39865801]\n",
      " [ 0.48691022]\n",
      " [ 0.38041356]\n",
      " [ 0.34124929]\n",
      " [ 0.28334635]\n",
      " [ 0.48536271]\n",
      " [ 0.42030329]\n",
      " [ 0.29054379]\n",
      " [ 0.27619085]\n",
      " [ 0.24866584]\n",
      " [ 0.28410611]\n",
      " [ 0.47881359]\n",
      " [ 0.55191249]\n",
      " [ 0.4432162 ]\n",
      " [ 0.34134707]\n",
      " [ 0.42370602]\n",
      " [ 0.44478935]\n",
      " [ 0.37456059]\n",
      " [ 0.48610631]\n",
      " [ 0.31382126]\n",
      " [ 0.42512038]\n",
      " [ 0.22908363]\n",
      " [ 0.14515373]\n",
      " [ 0.16288912]\n",
      " [ 0.24400342]\n",
      " [ 0.44551295]\n",
      " [ 0.35988358]\n",
      " [ 0.35780841]\n",
      " [ 0.43995011]\n",
      " [ 0.49812919]\n",
      " [ 0.27137518]\n",
      " [ 0.27534753]\n",
      " [ 0.57865953]\n",
      " [ 0.43493861]\n",
      " [ 0.25462162]\n",
      " [ 0.43367308]\n",
      " [ 0.17992587]\n",
      " [ 0.23899029]\n",
      " [ 0.46930125]\n",
      " [ 0.43242908]\n",
      " [ 0.51285738]\n",
      " [ 0.6361897 ]\n",
      " [ 0.23839262]\n",
      " [ 0.43745622]\n",
      " [ 0.31380749]\n",
      " [ 0.30892393]\n",
      " [ 0.35046926]\n",
      " [ 0.35892928]\n",
      " [ 0.55497324]\n",
      " [ 0.31274167]\n",
      " [ 0.2782506 ]\n",
      " [ 0.34940466]\n",
      " [ 0.15477715]\n",
      " [ 0.35351467]\n",
      " [ 0.32985768]\n",
      " [ 0.509426  ]\n",
      " [ 0.30466053]\n",
      " [ 0.26404065]\n",
      " [ 0.44777682]\n",
      " [ 0.33180675]\n",
      " [ 0.34505075]\n",
      " [ 0.36711439]\n",
      " [ 0.36763814]\n",
      " [ 0.23054422]\n",
      " [ 0.38908008]\n",
      " [ 0.42281836]\n",
      " [ 0.48226365]\n",
      " [ 0.39736673]\n",
      " [ 0.48188823]\n",
      " [ 0.23461241]\n",
      " [ 0.47389206]\n",
      " [ 0.33944988]\n",
      " [ 0.34615061]\n",
      " [ 0.37430587]\n",
      " [ 0.42107379]\n",
      " [ 0.42771456]\n",
      " [ 0.24792841]\n",
      " [ 0.19778255]\n",
      " [ 0.5039224 ]\n",
      " [ 0.430733  ]\n",
      " [ 0.48107749]\n",
      " [ 0.49626574]\n",
      " [ 0.44492674]\n",
      " [ 0.33184418]\n",
      " [ 0.35317731]\n",
      " [ 0.34757271]\n",
      " [ 0.39544716]\n",
      " [ 0.3754856 ]\n",
      " [ 0.28338009]\n",
      " [ 0.18563825]\n",
      " [ 0.52713633]\n",
      " [ 0.35054138]\n",
      " [ 0.30473879]\n",
      " [ 0.17820805]\n",
      " [ 0.48295602]\n",
      " [ 0.42393535]\n",
      " [ 0.5150438 ]\n",
      " [ 0.3245694 ]\n",
      " [ 0.57531625]\n",
      " [ 0.53781241]\n",
      " [ 0.43413246]\n",
      " [ 0.31858653]\n",
      " [ 0.54733413]\n",
      " [ 0.49341398]\n",
      " [ 0.23192081]\n",
      " [ 0.19302996]\n",
      " [ 0.37952322]\n",
      " [ 0.2414159 ]\n",
      " [ 0.44537392]\n",
      " [ 0.2283951 ]\n",
      " [ 0.29652151]\n",
      " [ 0.28532404]\n",
      " [ 0.34764457]\n",
      " [ 0.4883984 ]\n",
      " [ 0.1712365 ]\n",
      " [ 0.27799359]\n",
      " [ 0.27989605]\n",
      " [ 0.27409849]\n",
      " [ 0.36368096]\n",
      " [ 0.40296215]\n",
      " [ 0.16732158]\n",
      " [ 0.51133573]\n",
      " [ 0.24412535]\n",
      " [ 0.49212331]\n",
      " [ 0.41624355]\n",
      " [ 0.40745991]\n",
      " [ 0.39230815]\n",
      " [ 0.41238603]\n",
      " [ 0.49456304]] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct (Y):  [[ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]] \n",
      "Accuracy:  0.475626\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    feed = {X: x_data, Y: y_data}\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict=feed)\n",
    "        if step%200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict=feed))\n",
    "            \n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict=feed)\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $S(y_i)=\\frac{e^{y_{i}}}{\\sum_{j}{e^{y_{j}}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function: Cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $L = \\frac{1}{N}\\sum_i{D(S(WX_i+b), L_i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.96558\n",
      "200 1.69436\n",
      "400 0.95982\n",
      "600 0.784593\n",
      "800 0.693133\n",
      "1000 0.632706\n",
      "1200 0.589478\n",
      "1400 0.556756\n",
      "1600 0.530838\n",
      "1800 0.509555\n",
      "2000 0.491569\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5], [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7]]\n",
    "y_data = [[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        if step%200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test & one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "all = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9],\n",
    "                                          [1, 3, 4, 3],\n",
    "                                          [1, 1, 0, 1]]})\n",
    "print(all, sess.run(tf.arg_max(all, 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
